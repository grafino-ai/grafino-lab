Today, with AI, “a prompt is enough”: a few well-chosen words, ten seconds of waiting, and the image appears. But between a pretty picture and a visual that actually works in ADV campaigns lies an entire structured workflow that no one sees, everything that happens before and after those ten seconds.

The generation is instantaneous. The direction that leads to it is not.

What I’m sharing here is the workflow I use every day: an eight-stage process that blends analog method, critical eye, and AI tools.
A useful spark for anyone redefining their creative process in this hybrid era? Hopefully!

1. Read the brief, really read it
It sounds obvious, but the first thing to do is read the brief from start to finish. Don’t ask the AI to summarize it right away, you’ll do that later, but never before.

This phase anchors you in the project, lets you absorb context, and keeps your interpretative ability active, which is crucial for everything that follows.
This is where the quality of future decisions is established.

Technology can summarize, but it cannot understand.
A brief must be interpreted, not delegated

2. “Clean” the brief with AI, but never trust it blindly
Once you’ve absorbed the content of the brief, linguistic AI comes into play. I use targeted prompts to:

synthesize data

sharpen the critical points

surface insights

remove noise and redundancy

The goal: turn the brief from a static document into an operational base for brainstorming.

But there’s a catch: AI can hallucinate missing data, filling informational gaps with statistically plausible assumptions.

For example, if the brief does not specify where the target purchases the product, AI will confidently propose “online,” “in supermarkets,” or “in boutiques”, credible, coherent… and completely invented. And you risk building an entire campaign on a false assumption.

That’s why every synthesis must be read, corrected, verified, tightened.

Use AI to structure the brief, not to decide what’s true.
A model never reasons about content: it predicts based on statistics.

3. Brainstorming: training the machine like a creative assistant
Once insights are clear and boundaries defined, you can start a supported brainstorming phase. Here the AI assistant becomes incredibly helpful, especially if you work solo: always available, tireless, capable of generating huge volumes of material.

But quality requires one thing first: the assistant must be trained.
It needs:

context

references

objectives

limits

tone

language

A generic model produces generic ideas, good for anyone, and therefore useless for a specific client. A model trained on the project produces relevant, strategic stimuli.

With proper setup, this becomes a highly productive moment: metaphors, narrative angles, visual directions, conceptual hypotheses emerge in abundance.
But the quality depends entirely on how well the AI has been educated.
Without training, brainstorming becomes noise; with training, it becomes value.

Don’t ask the machine “give me ideas about X.”
Train the assistant as you would train a real junior.

4. From plausible idea to living idea: selection, stress-testing, refining
Are all AI-generated ideas good? Of course not.
Out of 50 ideas, 40 are plausible, 8 are formally correct, 2 are interesting… and maybe 1 can move forward.

This phase is about selection and sharpening.
I ask the AI to:

simulate consumer objections

compare concepts with competitors

push solutions beyond the limits of plausibility

shift tone, perspective, metaphor

“Make it more engaging” is meaningless.
This work requires specific back-and-forth, altering angles, pushing boundaries until that “something” finally appears, the spark worth pursuing.

AI should not simply be queried; it must be contradicted, pressured, stretched.
The unseen emerges when you stop settling for the first plausible idea.

5. Thinking what to draw: designing the Key Visual in words
Once creative directions are set, it’s time to design the Key Visual.
This is not yet about generating images, it’s about writing what you want to see, describing a full potential scene.

The work includes:

main and secondary subjects

the underlying visual metaphor

atmosphere and emotional tone

style (photographic, illustrated, hybrid)

composition (framing, focus, hierarchy)

technical aspects (close-ups, depth of field, lighting direction)

relationship between subject and environment

You stay here until the description becomes clear, solid, readable—ready to be translated into a technical prompt for the chosen image model.

Before opening a generator, know exactly what you want to visualize.
The quality of the visual comes from the clarity of the description, not from the tool.

6. Translating the description into a technical prompt: speaking the machine’s language
Once the scene is defined, it must be converted into the generator’s language. Linguistic AI is excellent at this: it “speaks” to its visual counterparts better than we do, optimizes parameters, removes clutter, and structures information for maximum interpretability. The technical prompt becomes a distilled, optimized version of your visual intention.

Creating dedicated assistants for each model helps achieve results consistent with your visual style, not flattened into generic, trendy aesthetics.

Use AI to craft technical prompts, but keep control of the visual language.
Standardized automation is always recognizable.

7. Generation, iteration, selection: the rally between AI and human eye
With the prompt ready, the image generator produces the first variants, usually four. Rarely does the first batch match the final goal; it’s only the beginning.

What follows is a continuous rally:
analyze output → adjust prompt → regenerate → refine → repeat.

Linguistic AI and visual AI alternate in a cross-dialogue until, among dozens of similar images, one stands out: the one that carries the intention of the brief.

But the choice is entirely human. No model can decide: “This is the right visual for this brand, in this context, at this moment.”

Don’t expect AI to “give you” the perfect image.
Each output is just another step toward a decision that remains yours.

8. Technical checks and manual refining: from draft to final Key Visual
When an image finally emerges as a candidate, it is not ready, it is only promising.

A technical and qualitative evaluation begins: high-resolution checks, artifact detection, deformation correction, palette assessment, emotional coherence, adherence to brand guidelines. Then come brand safety and copyright risks check.

And then comes the part many forget: returning to traditional tools. Photoshop, Illustrator, typography, manual composition, they are still essential.

This is where you:

remove imperfections

balance colors

integrate logo and copy

insert products correctly

prepare all campaign formats (print, web, social)

Only after this work can the visual be considered a true Key Visual, not just a “nice picture from afar.”

Treat the AI-generated image as an advanced draft, not the final file.
Professionalism lies in the steps that make it precise, intentional and 100% brand-ready.

AI generates an image in seconds.
The workflow leading to those seconds requires time, method and hybrid expertise.

And that is where the real value of this profession resides.
